<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Code Climbing</title>
	<atom:link href="http://OFFLINEZIP.wpshofeed/" rel="self" type="application/rss+xml" />
	<link>https://OFFLINEZIP.wpsho</link>
	<description>Samuele Agostinelli&#039;s Blog - Reaching the Heights</description>
	<lastBuildDate>Mon, 13 Apr 2020 01:44:54 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.4</generator>

<image>
	<url>http://OFFLINEZIP.wpshowp-content/uploads/2020/03/cropped-favicon-32x32.png</url>
	<title>Code Climbing</title>
	<link>https://OFFLINEZIP.wpsho</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>What&#8217;s in a CID? Multi, Multi, Multi&#8230;</title>
		<link>http://OFFLINEZIP.wpshowhats-in-a-cid-multi-multi-multi/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=whats-in-a-cid-multi-multi-multi</link>
					<comments>http://OFFLINEZIP.wpshowhats-in-a-cid-multi-multi-multi/#respond</comments>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Mon, 13 Apr 2020 01:41:54 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<guid isPermaLink="false">http://OFFLINEZIP.wpsho?p=91</guid>

					<description><![CDATA[Every piece of data on IPFS can be referenced through its CID, which stands for Content IDentifier. You might have have spotted some while navigating the IPFS jungle. They look... <a href="http://OFFLINEZIP.wpshowhats-in-a-cid-multi-multi-multi/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-large is-resized"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-1024x681.jpg" alt="content-identifier" class="wp-image-93" width="784" height="521" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-1024x681.jpg 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-300x199.jpg 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-768x511.jpg 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-1536x1021.jpg 1536w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-2048x1362.jpg 2048w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/white-product-label-1111319-624x415.jpg 624w" sizes="(max-width: 784px) 100vw, 784px" /></figure>



<p>Every piece of data on IPFS can be referenced through its CID, which stands for Content IDentifier. You might have have spotted some while navigating the IPFS jungle. They look like this: Qmd286K6pohQcTKYqnS1YhWrCiS4gz7Xi34sdwMe9USZ7u and this QmYf4sT9KbtW3ZCKoX8DdgJy9tDKVAUjbPTBi525RNR29V. And also this: bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi.<br></p>



<p>But what are they made of? How to understand their composition? CIDs are said to be multihash, multicodec and multibase.<br>Multi-what? In this short article, we&#8217;ll explain each of those terms so you can better understand CIDs.<br><br><br><strong>CIDs are&#8230; Multihash</strong><br>As has been explained on a previous <a href="http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-1-a-more-secure-and-efficient-internet/">article</a>, IPFS uses cryptographic hashes to identify data. Cryptographic hashes are in essence mathematical formulae that create a unique fingerprint for a data.<br></p>



<p>A popular cryptographic algorithm to generate such hashes is SHA2-256. SHA2-256 creates a hash of a length of 256 bits. It&#8217;s awesome and very useful today, but will it still be useful 10 years from now, when computing devices will become more powerful and where maybe quantum computing renders this particular algorithm useless?<br><br>This scenario is not not completely unheard of since some hash functions, such as MD5 and SHA-1, were eventually rendered useless.</p>



<p>So which algorithm should IPFS use, knowing that eventually the algorithm could be broken? The solution is to use a multihash.</p>



<p><br>The multihash is very simple. It consists of an identifier for the hashing function used, the length of the hashing function and then the hash itself.</p>



<p>The hashing function used is determined thanks to a table that everyone agrees on, where we assign a number to all possible hashing funtions.</p>



<p>So the multihash ends up looking like this: &lt;hashing function identifier&gt;&lt;length of the hash&gt;&lt;the hash&gt;<br>In the case of a SHA2-256 hash, this is &lt;SHA2-256&gt;&lt;256 bits in length&gt;&lt;001010101010&#8230;&gt;.<br><br>Awesome! Now our content identifiers are future-proof! If we want to change the hashing function, we can!<br><br>But what if we could get a little more information from our CID? Like what the data represents?<br><br>That where the next part comes in&#8230;<br><br><strong>CIDs are&#8230; Multicodec</strong></p>



<p>We want to add more information to our CID so that we may have a better idea of the type of data. Is it a JSON data? CBOR? Something else?<br><br>So what we will do is very simple, we&#8217;ll just add more data in front of our multihash which will describe the codec according to a <a href="https://github.com/multiformats/multicodec/blob/master/table.csv">table</a>. This works in the same manner as the identifier of the hashing function for the multihash.</p>



<p>So now, our CID looks like this:<br><code>&lt;codec identifier>&lt;multihash></code><br><br>The CID is just a long series of bits that are self-describing. First, the multicodec which describes the type of the data. Then, the multihash, as explained earlier.<br><br>But there&#8217;s more&#8230;<br><br><strong>CIDs are&#8230; Multibase</strong><br>Originally, IPFS CIDs were described in <a href="https://en.wikipedia.org/wiki/Base58">base58</a> which is the same base which encodes bitcoin addresses.<br>But of course, we could be using all kind of bases such as base 32 so, once again, we need to add more data in front of our CID. We now add the multibase, which just tells us the base which will encode the CID.<br><br><code>&lt;multibase>base(&lt;multicodex>&lt;multihash>)</code><br><br>Okay, so that&#8217;s it with prefixing data, right? We are done?<br><br>No&#8230; We need to do some history about CIDs first, before we can understand the last bit of information to add.</p>



<p><strong>V1 vs V0</strong></p>



<p>At the beginning of IPFS, there weren&#8217;t multibases or multicodecs. All the CIDs were multihashes only.<br>We call those CIDs version 0. Then later, the IPFS project decided to improve the CIDs and add the multicodec and the multibase also. And thus Version 1 replaced Version 0.<br><br>So how do we differentiate between Version 0 and Version 1 CIDs? How do we tell if a CID is of an upcoming hypothethical version 2? Or even version 3?<br><br>That&#8217;s why from Vversion 1 and onward it was decided to add the Version to all CIDs. We will now put it right after the multibase.<br>So now CIDs look like this:<br><br><code>&lt;multibase&gt;base(&lt;CID version&gt;&lt;multicodec&gt;&lt;multihash&gt;)</code></p>



<p><strong>BAFY vs Qm</strong><br><br>To help you synthesise this information, here&#8217;s an awesome tool that will allow you to analyse CIDs and each of their components: <a href="https://cid.ipfs.io/">https://cid.ipfs.io/</a><br><br>What I want you to do is to plug this version 0 CID in the tool: Qmd286K6pohQcTKYqnS1YhWrCiS4gz7Xi34sdwMe9USZ7u<br><br>As you might notice, the multicodec and the multibase is <code>implicit</code>. Why is that? Because they didn&#8217;t exist for version 0 CIDs! Therefore, we just assume what they are.</p>



<p>At the bottom of the page, you will see a hash starting with <code>bafy...</code> this hash is the equivalent CID for version 1. A neat trick to differentiate v0 and v1 CIDs is to look at the first letters. If it starts with Qm, it is probably a v0 CID. If it starts with bafy, it is probably a v1 CID.<br><br>Finally, plug this version 1 CID into the tool: bafybeigdyrzt5sfp7udm7hu76uh7y26nf3efuylqabf3oclgtqy55fbzdi.<br><br>The tool with now show us the base and codec according to the format described above.<br><br><strong>Congrats!</strong><br><br>Congrats! You are now a master of CIDs! You understand the ins and out of IPFS CIDs and can describe each component.</p>
]]></content:encoded>
					
					<wfw:commentRss>http://OFFLINEZIP.wpshowhats-in-a-cid-multi-multi-multi/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Automate your Builds on Docker Hub by Writing a Build Hook Script!</title>
		<link>http://OFFLINEZIP.wpshoautomate-your-builds-on-docker-hub-by-writing-a-build-hook-script/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=automate-your-builds-on-docker-hub-by-writing-a-build-hook-script</link>
					<comments>http://OFFLINEZIP.wpshoautomate-your-builds-on-docker-hub-by-writing-a-build-hook-script/#respond</comments>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Mon, 06 Apr 2020 01:04:47 +0000</pubDate>
				<category><![CDATA[Docker]]></category>
		<category><![CDATA[automation]]></category>
		<category><![CDATA[builds]]></category>
		<category><![CDATA[docker]]></category>
		<category><![CDATA[docker hub]]></category>
		<guid isPermaLink="false">http://OFFLINEZIP.wpsho?p=84</guid>

					<description><![CDATA[Docker Hub is like Github for Docker images, making all our lives way easier. Yet, it can quickly become a nightmare to maintaining multiple docker images. We don&#8217;t want to... <a href="http://OFFLINEZIP.wpshoautomate-your-builds-on-docker-hub-by-writing-a-build-hook-script/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/dockerhub-1024x435.png" alt="" class="wp-image-85" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/dockerhub-1024x435.png 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/dockerhub-300x128.png 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/dockerhub-768x326.png 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/dockerhub-624x265.png 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/dockerhub.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>Docker Hub is like Github for Docker images, making all our lives way easier.</p>



<p>Yet, it can quickly become a nightmare to maintaining multiple docker images. We don&#8217;t want to build the images manually each time we make a change to the Dockerfile. Also, we might want to support multiple variations of the same Docker image. For example, to support multiple node versions.<br><br>So good thing you&#8217;ve found this tutorial!</p>



<p>In the next few minutes, we will see how we can automate our builds by connecting our Docker Hub repo to a Github repo for automated builds. Finally, we&#8217;ll go deeper on the subject by exploring advanced options such as writing a build script that will give us complete control on the building process.<br><br>And you will then ascend to Docker Godhood!</p>



<p><strong>Connecting a Github Repo to Docker Hub</strong><br>The simplest way to automate your builds is to connect a Github repo containing a Dockerfile to your Docker Hub repo.</p>



<p>Here you can see I created a Github repo with a simple Dockerfile.<br><a href="https://github.com/SamueleA/docker-hub-auto-build-tutorial">https://github.com/SamueleA/docker-hub-auto-build-tutorial</a><br>(ignore the build folder for now I will explain soon)</p>



<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-27-56-1024x237.png" alt="" class="wp-image-86" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-27-56-1024x237.png 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-27-56-300x70.png 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-27-56-768x178.png 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-27-56-624x145.png 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-27-56.png 1433w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption>Configuring automated builds is quick and easy</figcaption></figure>



<p><br>Now, that you have a Github repo go to Docker Hub, click on your repo and, in the <strong>build</strong> tab, click on <strong>Configure Automated Builds</strong>.<br><br>Then, select your repo, fill the form and&#8230;that&#8217;s it!<br><br>When you will push a commit to your Github repo, Docker Hub will detect the commit and build a new image from your Dockerfile.<br><br>But that is still limiting, isn&#8217;t it?</p>



<p>What about the situation in which I have this Dockerfile that depends on a node version and maybe I want to support ALL the node versions, not just one. Maybe we could specify the node version in the docker tag. Do I then need to create multiple Dockfile? It would be so much easier if there was a way to only modify one Dockerfile and have that Dockerfile generate all the images for all the node versions&#8230;<br><br>That&#8217;s where build hooks come in.<br><br><strong>Hooks: Complete Control on the Build Process!</strong><br>So our goal is simple. We&#8217;ll have one Dockerfile and we will want to have it specify the node version through the docker tag, then Docker Hub will generate all the builds based on the tags.<br><br>For instance, <em>my-image:node-10</em> will use node 10, <em>my-image:node-11</em> will use node 11 and <em>my-image:latest</em> will use the latest version available.<br><br>We will need a build hook for that. The build hook will replace Docker Hub&#8217;s build process with our own by running a bash script.<br><br>Let&#8217;s start by creating a folder called <strong>hooks</strong> and a file called <strong>build</strong> inside that folder, just like in my <a href="https://github.com/SamueleA/docker-hub-auto-build-tutorial">example repo</a>. Then copy the following code in the <strong>build</strong> file:</p>



<pre class="wp-block-code"><code>#!/bin/bash

NODE_VERSION=$(echo $DOCKER_TAG | cut -d "-" -f2)

if &#91; $DOCKER_TAG == "latest" ]
then
  docker build . --build-arg NODE_VERSION=${DOCKER_TAG} -t ${IMAGE_NAME}
else
  docker build . --build-arg NODE_VERSION=${NODE_VERSION} -t ${IMAGE_NAME}
fi
</code></pre>



<p><strong>Build</strong> is a script written in bash, hence the first line of code. It reads the environment variable DOCKER_TAG and figures out the node version specified (just like we said we would by formatting our Docker tag in the format <em>my-image:node-VERSION</em>).<br><br>This DOCKER_TAG variable is set by Docker Hub itself. You can find a list of all the other environment variables made available by Docker Hub <a href="https://docs.docker.com/docker-hub/builds/advanced/">here</a>.</p>



<p>Then, there&#8217;s an if statement. Basically, it&#8217;s to deal with the case when the docker tag is <strong>latest</strong>. In that case, we&#8217;ll simply use the latest node version. In any case, depending on the docker tag, we are going to pass an argument to our build with the <strong>&#8211;build-arg</strong> flag.<br><br>Now, if you look at the Dockerfile in my Github repo:</p>



<pre class="wp-block-code"><code>ARG NODE_VERSION

FROM node:$NODE_VERSION</code></pre>



<p>We are calling the variable NODE_VERSION which we&#8217;ve just set earlier with the docker build command inside our build script!<br><br>Now, in the build settings on Docker Hub, all I&#8217;ll have to do is to set the name of the Docker tags according to our convention and all my images will build automatically! I can support pretty much any node version without the headache of maintaining multiple Dockerfile!</p>



<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-25-01-1024x595.png" alt="" class="wp-image-87" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-25-01-1024x595.png 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-25-01-300x174.png 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-25-01-768x447.png 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-25-01-624x363.png 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/04/Screenshot-from-2020-04-05-20-25-01.png 1419w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure>



<p>And here is my Docker Hub repo, if you want to see the final builds: <a href="https://hub.docker.com/repository/docker/samueleago/auto-build-tutorial">https://hub.docker.com/repository/docker/samueleago/auto-build-tutorial</a><br><br>As you can imagine, the limit is your imagination at this point. You can have your build script do whatever you envision it to do! And if you are an amazing Bash scripter&#8230; knock yourself out with the amazing control it gives you!!</p>



<p><strong>Automate Away!</strong></p>



<p>Hopefully, this tutorial was useful to you and you can now automate your Docker Images for your projects!<br><br>Automate! Automate! Automate!</p>
]]></content:encoded>
					
					<wfw:commentRss>http://OFFLINEZIP.wpshoautomate-your-builds-on-docker-hub-by-writing-a-build-hook-script/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Docker for Newbz: Create a Docker Image for Your App!</title>
		<link>http://OFFLINEZIP.wpshodocker-for-newbz-create-a-docker-image-for-your-app/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=docker-for-newbz-create-a-docker-image-for-your-app</link>
					<comments>http://OFFLINEZIP.wpshodocker-for-newbz-create-a-docker-image-for-your-app/#respond</comments>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Mon, 30 Mar 2020 01:15:33 +0000</pubDate>
				<category><![CDATA[Docker]]></category>
		<category><![CDATA[docker]]></category>
		<category><![CDATA[tutorial]]></category>
		<guid isPermaLink="false">http://OFFLINEZIP.wpsho?p=60</guid>

					<description><![CDATA[Every programmer dreads the phrase: &#8220;But it works on my machine!!!&#8221; Our poor developer now knows that he must now figure out what&#8217;s wrong among a bazillion things. &#8220;Okay, so... <a href="http://OFFLINEZIP.wpshodocker-for-newbz-create-a-docker-image-for-your-app/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/1_9hGvYE5jegHm1r_97gH-jQ-1024x819.png" alt="" class="wp-image-66" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/1_9hGvYE5jegHm1r_97gH-jQ-1024x819.png 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/1_9hGvYE5jegHm1r_97gH-jQ-300x240.png 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/1_9hGvYE5jegHm1r_97gH-jQ-768x614.png 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/1_9hGvYE5jegHm1r_97gH-jQ-624x499.png 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/1_9hGvYE5jegHm1r_97gH-jQ.png 1240w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption>Fellow newb, welcome to Docker!</figcaption></figure>



<p>Every programmer dreads the phrase: &#8220;But it works on my machine!!!&#8221; Our poor developer now knows that he must now figure out what&#8217;s wrong among a bazillion things. &#8220;Okay, so what&#8217;s your OS? I hope there&#8217;s not a quirk with the OS. What about your node version? Maybe the app only works with this specific node version. Etc&#8230;&#8221;<br><br>Just thinking about it wakes up my problem-solving PTSD developed from many wasted hours trying to figure out what&#8217;s wrong with a setup.<br><br>And that&#8217;s where Docker comes in. Docker sets a common environment that never changes for us to run our app into. If it works on my machine with the Docker image&#8230; it will work on yours!<br><br>In this tutorial, we&#8217;ll create a simple create-react-application and then we&#8217;ll run it in a Docker Container. <br><br>Container? Image? Are you confused? You&#8217;re at the right place because this tutorial is for newbz with a z at the end.<br><br>Let&#8217;s get started.<br><br><strong>Docker Image vs Docker Container</strong><br>Just to clarify this real quick. A docker container is an instance of a docker image. In the same manner that a built house (container) is an instance of the architect&#8217;s plans (image).<br><br>Simple, right?<br><br>NEXT!<br><br><strong>Making our First Image</strong><br><br>I just want to say that in this tutorial I am assuming you have everything installed already. You should have Node.js, create-react-app and Docker. You&#8217;re a big boy. I know you can do that without me. Install all that and come back.<br><br>So to start, we&#8217;ll create a simple React application.<br></p>



<pre class="wp-block-code"><code>npx create-react-app my-app
cd my-app</code></pre>



<p>Cool now we got a React application. Our goal with this tutorial will be to run &#8220;npm run start&#8221; and then see our web page while it runs in the container.<br><br>Now, we want to create a Docker Image. How do we do that? We must specify instructions to give to Docker on how to build the image. This is done in a <em>Dockerfile</em>.<br>Create an empty file inside the React application and call it &#8220;Dockerfile&#8221;.<br><br>Now, let&#8217;s fill that Dockerfile. The comment on top of the line will explain what it does</p>



<pre class="wp-block-code"><code># This is the base image. In this case, we are taking a Linux image with node 11. This image is pulled from Docker Hub. https://hub.docker.com/_/node/
FROM node:11

# This will be the directory in which commands such as COPY and RUN will be run.
WORKDIR /app

#This means we copy everything in the current folder (our React application) into the folder defined previously in WORKDIR
COPY . .

# RUN means we run commands in the command line during build time. In this case, we have npm, because it is included in the base docker image. If we didn't have it, we'd have to use RUN to run commands to install node.
RUN npm install

# CMD defines a run-time operation. In this case we want to start the webserver
CMD ["npm", "run", "start"]
</code></pre>



<p>Did we make a mistake while creating our Dockerfile? Let&#8217;s try building our image!</p>



<pre class="wp-block-code"><code>docker build . -t my-app</code></pre>



<p>The command above builds the image from the content of the Dockerfile (since I am assuming the current directory is the one containing the app). The argument &#8220;-t my-app&#8221; means we want to give our image the tag &#8220;my-app&#8221;, which will let us refer to our image more easily. After letting the build run, the command line shows:<br></p>



<pre class="wp-block-code"><code>Successfully built 82322ef0e172
Successfully tagged my-app:latest</code></pre>



<p>That means success! &#8220;82322ef0e172&#8221; is the image id and &#8220;my-app&#8221; is the tag we defined above in the build command.</p>



<p>Remember the difference between IMAGE and CONTAINER describe above? Right now we have an image, not a container. We got the plans of the house, we just need to build it so our app can live in it!</p>



<pre class="wp-block-code"><code>docker run -dit -p 3000:3000 --name my-app --rm my-app</code></pre>



<p>Let&#8217;s dissect the command above.<br>-dit : This will run our container in detached mode running in the background after execution of the commands in the Dockerfile. Without -dit, the container wouldn&#8217;t still be running. It would stop as soon as all the commands are run.<br><br>-p 3000: 3000 : This maps port 3000 on our local machine to port 3000 on our docker container. 3000 is the port that the create-react-app web server runs on by default.<br><br>&#8211;name my-app: This is the name we want to give to our container<br><br>&#8211;rm: This means we wants to delete the container once it has stopped running.<br><br>my-app: The name of the image that will serve as basis for the container<br><br>Now do:</p>



<pre class="wp-block-code"><code>docker ps</code></pre>



<p>This will list all the running containers. You should be able to see a container name my-app alongside other information such as the container id.<br><br>The last step is to admire our final result. Go to http://localhost:3000 and you will see your app running!</p>



<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Screenshot-from-2020-03-29-10-40-48-1024x534.png" alt="" class="wp-image-64" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Screenshot-from-2020-03-29-10-40-48-1024x534.png 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Screenshot-from-2020-03-29-10-40-48-300x156.png 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Screenshot-from-2020-03-29-10-40-48-768x400.png 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Screenshot-from-2020-03-29-10-40-48-624x325.png 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Screenshot-from-2020-03-29-10-40-48.png 1514w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption>This is the React application running from inside our docker container!</figcaption></figure>



<p><strong>Have fun!</strong><br>Docker is an important technology to know about so I hope this was useful to you! Also, here is a github with the react app and dockerfile used in this tutorial: <a href="https://github.com/SamueleA/docker-tutorial">https://github.com/SamueleA/docker-tutorial</a></p>
]]></content:encoded>
					
					<wfw:commentRss>http://OFFLINEZIP.wpshodocker-for-newbz-create-a-docker-image-for-your-app/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>The IPFS Holy Grail Part 2: Decentralisation and Censorship Resistance</title>
		<link>http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-2-decentralisation-and-censorship-resistance/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=the-ipfs-holy-grail-part-2-decentralisation-and-censorship-resistance</link>
					<comments>http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-2-decentralisation-and-censorship-resistance/#respond</comments>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Mon, 23 Mar 2020 02:02:18 +0000</pubDate>
				<category><![CDATA[IPFS]]></category>
		<category><![CDATA[decentralisation]]></category>
		<guid isPermaLink="false">http://OFFLINEZIP.wpsho?p=42</guid>

					<description><![CDATA[This is the second and last part in a discussion of how IPFS plans to fix the internet&#8217;s biggest problems.In the previous part, we&#8217;ve discussed how IFPS makes the web... <a href="http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-2-decentralisation-and-censorship-resistance/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<p></p>



<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abstract-art-blur-bright-373543-1-1-1024x682.jpg" alt="" class="wp-image-56" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abstract-art-blur-bright-373543-1-1-1024x682.jpg 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abstract-art-blur-bright-373543-1-1-300x200.jpg 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abstract-art-blur-bright-373543-1-1-768x512.jpg 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abstract-art-blur-bright-373543-1-1-624x416.jpg 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abstract-art-blur-bright-373543-1-1.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption>The future is distributed!</figcaption></figure>



<p>This is the second and last part in a discussion of how IPFS plans to fix the internet&#8217;s biggest problems.<br>In the previous part, we&#8217;ve discussed how IFPS makes the web more secure and efficient.<br><br>This week we&#8217;ll discuss how IPFS addresses concerns with centralisation and censorship on the internet.</p>



<p><strong>Decentralisation: An Actual Web for the Web</strong><br><br>As the saying goes, do not put your eggs in the same basket! Sadly, that is exactly how the modern internet is organised. All the eggs, the data, are stored in these massive baskets, the servers, to which clients must connect to.<br><br>This arrangement makes the system fragile, as a problem with the server means clients cannot access anything at all. It also means that, if there is a sudden influx of egg hungry connoisseur, the basket will not have enough throughput to feed everyone. We can imagine a long line of people waiting to be fed, each having to wait for the one in front to pluck his own egg.<br><br>The secret, therefore, for IPFS is simply to not put the eggs in the same basket! In fact, eggs are spread over a distributed network of baskets.<br><br>But enough with the eggs&#8230; long story short, IPFS is <em>distributed network</em>. As such, it falls in the line of other peer-to-peer protocols such as BitTorrent.<br><br></p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/ifps.jpg" alt="" class="wp-image-54" width="364" height="331" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/ifps.jpg 364w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/ifps-300x273.jpg 300w" sizes="(max-width: 364px) 100vw, 364px" /></figure></div>



<p><br>This has an important consequences. Since the network doesn&#8217;t depend on a single server, computers can go online and offline and the network will still function.<br><br>Think about a scenario in which we want to connect to Facebook, but the servers are down. We can&#8217;t connect, since connection depends on the server being available.<br><br>On the other hand, let&#8217;s imagine an IPFS-based version of Facebook. The data could live with some sort of encryption scheme on IPFS where the user possesses the keys to access his private data and is free to access other users&#8217; public data. In that case, there is NO WAY to prevent a user from connecting to the site and accessing his data. In effect, if a peer goes offline, there is another one that can possess the data.</p>



<p>That&#8217;s an amazing property that is only possible with IPFS.<br><br>Similarly, if a large amount of users want to access the same file in our current version of the web, it would cause a massive demand surge that might possibly strain a server to exhaustion. But in IPFS, the file can be shared peer-to-peer. Once a peer has a file, he can share it to another peer, and another.</p>



<p>The file will always be accessible even under high demand!<br><br>This is just like BitTorrent where popular files are made MORE accessible instead of LESS by virtue of the file&#8217;s data being shared among peers.<br><br>Speaking of BitTorrent, this leads us to the next point&#8230;<br><br><strong>Censorship Resistance: True Freedom of Information</strong><br><br>We mentioned BitTorrent earlier. Isn&#8217;t it amazing that authorities were never able to shut it down, despite the breaches to the law through copyright infringement from distributing pirated movies, shows, songs and games?<br><br>No matter how hard governments try they cannot stop this soup of illegal activity that is BitTorrent.</p>



<p>Such is the power of a distributed network!</p>



<p>Since there is no central server to shutdown, authorities have no individual entity to attack. Everyone is a peer! So if one is stopped, there is another peer to replace it. And to attack everyone is, quite simply, unfeasible.<br><br>Of course, this means that IPFS could become a safe haven of illegal activities. There has been ideas brought forward to curb this negative side-effect of a distributed network of files, such as lists of blacklisted hashes. I personally doubt these solutions will have any effect. For instance, if someone were to blacklist the hash of an illegal file, what would stop someone from simply changing a pixel and, thus, the hash?<br><br>There could be an infinite amount of illegal hashes produced, making a blacklist list unrealistic.<br><br>Despite that, IPFS brings an important benefit: censorship resistance.<br><br>Since bad files cannot be stopped, neither can the good ones! It is open to interpretation whether this property will have a good or bad effects. Whether disinformation will drown out good information. Whether lies will bury truth.</p>



<p>My personal belief on this matter is that good ideas have a tendency to rise. Complete truth will never emerge from a purely distributed network yet, in average, there will be more good than bad. Not to mention that centralised systems have failed to kill off bad ideas. So why not favour uncensorable systems instead, and let users themselves sort through the data?<br><br>Also, certain innovations might work in conjunction with IPFS to certify the truth about a piece of data. What if we saved important IPFS hashes to a blockchain system such as Ethereum? This will mean that the hash will also be associated with a truthful and unchangeable timestamp. We can associate an uncensorable file in a verifiable moment in time.</p>



<p>Let me explain why I find this exciting. We are talking a lot about deep fakes these days. Malicious individuals, and maybe even governments and agencies, modify pictures and videos in such manners to distort reality. Faced with an avalanche of contradictory images and videos, the truth becomes increasingly difficult to ascertain&#8230; but what if we had a timestamped hash of a file of the original picture or video? Suddenly, we can disprove any modified version of this file done AFTER the timestamp!<br><br>This should lead to greater access to verifiable truths.<br><br>But only time will tell whether I will end up being right or not about this.<br><br>And the Time that is coming, how exciting it will be!</p>
]]></content:encoded>
					
					<wfw:commentRss>http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-2-decentralisation-and-censorship-resistance/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>The IPFS Holy Grail Part 1: A More Secure and Efficient Internet</title>
		<link>http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-1-a-more-secure-and-efficient-internet/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=the-ipfs-holy-grail-part-1-a-more-secure-and-efficient-internet</link>
					<comments>http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-1-a-more-secure-and-efficient-internet/#comments</comments>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Mon, 16 Mar 2020 02:40:29 +0000</pubDate>
				<category><![CDATA[IPFS]]></category>
		<category><![CDATA[internet]]></category>
		<category><![CDATA[security]]></category>
		<category><![CDATA[web]]></category>
		<guid isPermaLink="false">http://OFFLINEZIP.wpsho?p=36</guid>

					<description><![CDATA[Last week we&#8217;ve discussed some of the problems related to our current iteration of the internet. It was pretty doom and gloom, but now we&#8217;ll discuss what IPFS will do... <a href="http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-1-a-more-secure-and-efficient-internet/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-large is-resized"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920-1024x750.jpg" alt="" class="wp-image-45" width="767" height="561" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920-1024x750.jpg 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920-300x220.jpg 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920-768x562.jpg 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920-1536x1125.jpg 1536w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920-624x457.jpg 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/evening-567840_1920.jpg 1920w" sizes="(max-width: 767px) 100vw, 767px" /><figcaption>IPFS is coming&#8230;</figcaption></figure>



<p><br><a href="http://OFFLINEZIP.wpshowhy-the-internet-is-falling-apart-and-the-need-for-ipfs/">Last week</a> we&#8217;ve discussed some of the problems related to our current iteration of the internet. It was pretty doom and gloom, but now we&#8217;ll discuss what IPFS will do to solve those problems, and thus, let us see the light at the end of the internet tunnel.<br><br>As a quick recap, here are the four problems we&#8217;ve identified with the internet last week: 1. its shaky security 2. its inefficiency in supplying increasing demand from users 3. it&#8217;s crippling centralisation 4. its proneness to censorship.</p>



<p>We will discuss security and efficiency. Let&#8217;s dive in!</p>



<p><strong>Security: No Need to Trust Anyone</strong></p>



<p>IPFS promises a secure internet by removing the necessity of trusting the honesty of a third-party. As such, all IPFS data is self-certifying, which simply means that the user is able to determine by himself that the data he receives is trustworthy.<br><br>The secret to this self-certification comes from the power of hashing functions. Hashing functions are special mathematical entities which, if inputted data, will output a unique fingerprint called <em>the</em> <em>hash</em>. <br><br>And by unique, we truly mean unique.</p>



<p>Theses functions are engineered in such a manner that it is so ridiculously improbable to find two pieces of data producing the same result, that it becomes in practice impossible to produce a forgery of the initial data.<br></p>



<p>The hash is to data what a fingerprint is to a human. It uniquely identifies an individual. However, we cannot reconstruct a person from a fingerprint. This means that the hash is a unique identifier that does not compromise the privacy of the original data. One cannot reproduce the data from the hash alone.<br></p>



<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Untitled-Diagram.png" alt="" class="wp-image-46" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Untitled-Diagram.png 759w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Untitled-Diagram-300x67.png 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/Untitled-Diagram-624x139.png 624w" sizes="(max-width: 759px) 100vw, 759px" /><figcaption>A hash function turns data into a unique fingerprint</figcaption></figure>



<p><br>Okay, so there&#8217;s this computer sciency math stuff&#8230; but what does it have to do with IPFS?</p>



<p>In HTTP, when the user, let&#8217;s say, goes to codeclimbing.com (a blog I highly recommend!! :D), the browser fetches the data at the LOCATION of the server of codeclimbing.com. This location can be spoofed by hackers. Maybe one can intercept the request and instead of sending the blog, he sends a phishing website trying to get a user&#8217;s password&#8230;<br></p>



<p>But with IPFS, the users will not ask for codeclimbing.com, but instead for a hash which looks something like this: QmTkzDwWqPbnAh5YiV5VwcTLnGdwSNsNTn2aDxdXBFca7D.<br></p>



<p>Supposing a hacker intercepted the request for QmTkzDwWqPbnAh5YiV5VwcTLnGdwSNsNTn2aDxdXBFca7D and tried to send a malicious phishing site, the user could run the received data through a hashing function, compare the hash of the received data with the requested hash, and reject the incoming data on the basis that the hashes do not match.<br><br>The evil hacker’s plan has been thwarted!</p>



<p>The consequences of such a scheme are immense. Data integrity is ALWAYS preserved.<br><br>If a user requests a legal document, not a single letter of that document will be different. If a user downloads a program, not a single 1 or a single 0 will differ. If the user requests a picture, every pixel will be at the exact same location, an interesting property in a time of deep fakes, where the authenticity of a picture can be difficult to ascertain.<br><br>This focus on using hashing functions to fetch data is called CONTENT addressing (because the content is hashed) as opposed to the aforementioned LOCATION addressing. I think you’ll agree, it’s way more secure that way.<br><br>That being said, there’s another important property that content addressing unlocks. And it&#8217;s&#8230;</p>



<p><strong>Efficiency &amp; Speed: The Digital Lamborghini</strong><br><br>There&#8217;s something missing from the explanation above which you might have already picked up on if you were exceptionally astute: since users ask for data based on the hash of its content instead of its location, how do we know where to find this data at all? Where IS the data? In which server exactly?</p>



<p>The answer is that the data can be anywhere. IPFS is a peer-to-peer network in which ANYONE can contribute. You can think of it like BitTorrent, the protocol often used to distribute pirated movies and songs.</p>



<p>And since anyone can distribute data, a user in the US, for example, doesn&#8217;t have to ask data to a faraway server in China, he can simply take this data from someone else near his geographical location, and vice-versa for the other way around. This is much more efficient, especially if the data is right next to the user, geographically speaking.<br><br>Suppose there is a room filled with 100 HTTP users and 100 IPFS users and they all want to go to codeclimbing.com (because it&#8217;s such a great blog! :D), how will their experiences differ?<br><br>The 100 HTTP users will make a request to the LOCATION of codeclimbing.com. Each of those requests, will go through the internet, bounce through a bunch of routers, until finally arriving at a server which is, in all probability, from Google and 1000s of kilometers away, the requested data is then sent from the server, bouncing back through a bunch of routers again, to finally arrive in the user&#8217;s hands.</p>



<p>What does the request look like, from the point of view of the IPFS users? The 100 IPFS users make a request to the IPFS network for the hash of the data. What if someone in the room has the file? Why bother going through routers and to a potentially remote server? That geographically near user can share it with another user and that user can share it with another one, and another one.<br><br>Content addressing is clearly much more efficient location addressing in this case! And of course, it&#8217;s all done in secure manner.</p>



<p><strong>On the Next Episode of&#8230;.</strong></p>



<p>It is possible to keep going deeper with those topics, but we will keep it at that for now. Hopefully, you had a good taste of what the distributed internet has to offer!<br><br>Come back next week and we will continue this discussion about how IPFS will solve two other problems of the Internet: centralisation and proneness to censorship.</p>



<p><br></p>
]]></content:encoded>
					
					<wfw:commentRss>http://OFFLINEZIP.wpshothe-ipfs-holy-grail-part-1-a-more-secure-and-efficient-internet/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Why the Internet is Falling Apart and the Need for IPFS</title>
		<link>http://OFFLINEZIP.wpshowhy-the-internet-is-falling-apart-and-the-need-for-ipfs/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=why-the-internet-is-falling-apart-and-the-need-for-ipfs</link>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Mon, 09 Mar 2020 02:09:59 +0000</pubDate>
				<category><![CDATA[IPFS]]></category>
		<category><![CDATA[essay]]></category>
		<category><![CDATA[web]]></category>
		<guid isPermaLink="false">http://OFFLINEZIP.wpsho?p=33</guid>

					<description><![CDATA[IPFS is fascinating. Expect to hear a lot more about this groundbreaking new tech in this blog. Over the upcoming weeks and months, we’ll discuss its philosophical underpinnings, why it... <a href="http://OFFLINEZIP.wpshowhy-the-internet-is-falling-apart-and-the-need-for-ipfs/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-large"><img src="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abandoned-airplane-apocalypse-crash-6709-1024x576.jpg" alt="" class="wp-image-74" srcset="http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abandoned-airplane-apocalypse-crash-6709-1024x576.jpg 1024w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abandoned-airplane-apocalypse-crash-6709-300x169.jpg 300w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abandoned-airplane-apocalypse-crash-6709-768x432.jpg 768w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abandoned-airplane-apocalypse-crash-6709-624x351.jpg 624w, http://OFFLINEZIP.wpshowp-content/uploads/2020/03/abandoned-airplane-apocalypse-crash-6709.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px" /><figcaption>Yes, the internet is collapsing just like that!</figcaption></figure>



<p>IPFS is fascinating. Expect to hear a lot more about this groundbreaking new tech in this blog. Over the upcoming weeks and months, we’ll discuss its philosophical underpinnings, why it even exists, what it consists of, how all of its pieces connect together and how to develop on top of it. All of it.<br><br>All. Of. It.<br><br>It’s going to be a wild ride and we’ll all be enriched by participating in the conversation. Yet, before we do any of that, here’s a question of the utmost importance:<br><br><strong>WTF is IPFS?</strong><strong><br></strong>Seriously, wtf is it? We’re dealing with complex tech here and discussing IPFS is like opening a can of worms with a black hole spitting fire from its event horizon. Yet, fundamentally, IPFS has a simple, yet audacious aim: <em>to re-architecture the entire internet by replacing http</em>.<br><br></p>



<p>Addresses on websites are often prefixed by HTTP. The goal of IPFS is to completely replace the HTTP protocol as the foundational layer of the internet.<br><br>You’ve heard it right. The whole web. In fact, our current version of the web is sometimes called Web2, and IPFS, its natural development, Web3.<br><br>But why re-architecture the whole web? Isn’t it fine as it is?<br><br>HELL NO!<br><br>The web is not fine! In fact, you might already be impacted by its design flaws.</p>



<p><strong>So, what’s wrong with the status quo of the web?</strong><br><br><strong><em>The current internet is SLOW and cannot support the upcoming wave of innovations and users</em></strong><strong>.</strong><br>The internet seriously needs more bandwidth. Think about the streaming 8k videos. We already need fast internet for that, but what about 16k and beyond? The demands on the web keep increasing and, let me tell you one thing, serving such content costs big $$$.<br><br></p>



<p>Companies like facebook, google and others, spend billions to support their web architecture and deliver its content to you. The costs are offloaded to users of course in various ways of course, and many applications that could have been useful for humanity cannot see the light of day because of this barrier.<br></p>



<p>But big files aren’t the only issue affecting the web. Think about the proliferation of devices connected to the internet: your computer, your phone, your tablet, even the television. As an increasing amount of devices are connected to the internet, so is the overhead required to serve those them.<br><br></p>



<p>And to make matters worse, the amount of devices connected to the web is expected to keep increasing. Not only are we talking about the masses of users coming from newly industrialized countries such as India, but from new concepts such as the internet of things. The internet of things aims to connect everything that’s around you, whether it’s the cars, the door of your house, the lights, the energy meters, etc… That’s an even bigger load on the internet.<br><br>We need an alternative that will scale exponentially, be efficient and be blazing fast.<br></p>



<p>We need IPFS.<br><br><strong><em>The other problem is security.</em></strong> How do I know that the content I am asking for is the content I asked for? What if an entity tampered with, let’s say, an image?<br></p>



<p>It may sound trivial at first glance, but the more technology progresses, new threats such as <a href="https://en.wikipedia.org/wiki/Deepfake">deep fakes</a>, will highlight this problem.<br><br>Yet there are more immediate threats than that. How do I know the website I am connecting to is the right one, and not a phishing attack by a malicious hacker? Currently, we have a system of certificate authority in place to prevent such events to occur, yet they require trust in a <a href="https://www.infoworld.com/article/2623829/weaknesses-in-ssl-certification-exposed-by-com">third-party that can easily be compromised.<br><br></a>The current system is fundamentally flawed.<br><br><strong><em>Another important problem with the internet is that it is heavily centralized. </em></strong>Let’s take the example of the monolithic facebook. Surely, such massive companies operated by the combined brainpower of our planet’s most brilliant engineers should work all the time and never crash…<a href="https://downdetector.com/status/facebook/map/">think again</a>.<br><br></p>



<p>Even facebook cannot be spared from breaking down and when that happens we are hit with the 404 page we all are so familiar with. The fundamental problem is that our current web implementation is based on the client-server model. Basically, a client, the browser, asks for data to a central server, such as facebook’s servers, and the server supplies the data.<br><br>This works wonderfully when no problem occurs, but when there’s a sudden influx of users, or a natural catastrophe, a hack, or even a simple bug in the code… It will crash.<br></p>



<p>And <em>nobody</em> can access their content anymore.<br><br><strong>Finally, the internet is prone to censorship.</strong> You might not care that much about this aspect. In fact, the reasons cited above should be more than enough to convince anyone that the internet needs to be fixed. Yet, it’s worth taking a moment and think about how much the internet influences us and the power such influence confers to internet censorship.<br><br></p>



<p>We are informed by the internet, we socialize on the internet, we bank on, we play on the internet and we work on the internet. One would be pained to find an area of life the web did not encroach upon.</p>



<p><br>Internet censorship could mean one of two things. Content could be censored by a megacorporation or even a government. That would be equivalent to letting someone else do the thinking for you by deciding which content and, therefore, which thoughts will be allowed in your mind.<br></p>



<p>That is scary in itself, yet the second type of censorship is even scarier: the ability to censor humans out of the internet. Imagine a content creator cut off from Youtube, or Medium, or Twitter. He loses his livelihood. Imagine you are removed from linkedIn, you cannot network anymore. Imagine you cannot use email? As the internet becomes ever more prevalent, so are the consequences of being disconnected from it.<br><br><strong>The solution is IPFS</strong><strong><br></strong>IPFS is an amalgamation of innovations that put together will solve many of humanity’s tech problems. It is similar to bitcoin in that sense, except that, instead of revolutionizing finance, it will revolutionize the internet and, by doing so, our lives.<br><br><strong>Stay tuned for more!</strong><strong><br></strong>In the next series of articles, we’ll see what solutions IPFS proposes to each of those problems. It will be a great way for you to be introduced to the terminology and concepts of IPFS.<br></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Welcome, and thanks for all the fish!</title>
		<link>http://OFFLINEZIP.wpshowelcome-and-thanks-for-all-the-fish/?utm_source=rss&#038;utm_medium=rss&#038;utm_campaign=welcome-and-thanks-for-all-the-fish</link>
					<comments>http://OFFLINEZIP.wpshowelcome-and-thanks-for-all-the-fish/#comments</comments>
		
		<dc:creator><![CDATA[TheCodeClimber]]></dc:creator>
		<pubDate>Sun, 01 Mar 2020 03:23:09 +0000</pubDate>
				<category><![CDATA[General]]></category>
		<guid isPermaLink="false">http:/?p=1</guid>

					<description><![CDATA[Welcome to my programming blog! I have no clue how you stumbled here, but am happy you did. In ten years from now, you will be bragging to your friends... <a href="http://OFFLINEZIP.wpshowelcome-and-thanks-for-all-the-fish/">Read more &#187;</a>]]></description>
										<content:encoded><![CDATA[
<p>Welcome to my programming blog!<br><br>I have no clue how you stumbled here, but am happy you did. In ten years from now, you will be bragging to your friends that you read the Code Climbing blog before anyone else did, before it was cool. You&#8217;ll be the most hipster of hipsters and your mom will be proud of you.<br><br>This is my personal blog. It is mine and no one else&#8217;s. I want it to be awesome of course, but also personal above that. So, I&#8217;ll only talk about things that interest me. Let&#8217;s hope the stars are aligned regarding what interests me and what interests you. More important than that, however, I hope my enthusiasm can travel through the internet, find where you live, come out of the screen screaming with a knife and kiss you on the cheeks.<br><br>So stay tuned for awesome (yes!) articles about web development and decentralised technologies. I would be happy if you learned something new reading my blog posts. I&#8217;ll share thoughts, ideas, struggles, talk about interesting technologies and tutorials.<br><br>Topics that might appear include frontend web development with React, backend web development and articles about cool interesting defi or decentralised tech like Ethereum, IPFS, bitcoin, etc&#8230;<br><br>I also enjoy actual rock climbing in addition to programming. It is a perfect analogy for our short lives in which we should always strive for more, whatever &#8220;more&#8221; might mean for you.<br><br>The goal is the write regularly so as to improve my writing chops and in so doing enrich the lives of others with interesting information and maybe even inspire you in the process. That way we can both be reaching new heights in our lives and finally get on top of that ever increasing mountain.<br><br>So come back regularly to see what&#8217;s new! Cheers!!!</p>
]]></content:encoded>
					
					<wfw:commentRss>http://OFFLINEZIP.wpshowelcome-and-thanks-for-all-the-fish/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
	</channel>
</rss>
